{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd91ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c821536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  891 non-null    int64\n",
      " 1   Survived     891 non-null    int64\n",
      " 2   Pclass       891 non-null    int64\n",
      " 3   Sex          891 non-null    int64\n",
      " 4   Age          891 non-null    int64\n",
      " 5   Fare         891 non-null    int64\n",
      " 6   Embarked     891 non-null    int64\n",
      " 7   Title        891 non-null    int64\n",
      " 8   IsAlone      891 non-null    int64\n",
      " 9   Age*Class    891 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 69.7 KB\n",
      "________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Pclass       418 non-null    int64\n",
      " 2   Sex          418 non-null    int64\n",
      " 3   Age          418 non-null    int64\n",
      " 4   Fare         418 non-null    int64\n",
      " 5   Embarked     418 non-null    int64\n",
      " 6   Title        418 non-null    int64\n",
      " 7   IsAlone      418 non-null    int64\n",
      " 8   Age*Class    418 non-null    int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 29.5 KB\n",
      "________________________________________\n",
      "[     PassengerId  Survived  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  \\\n",
      "0              1         0       3    0    1     0         0      1        0   \n",
      "1              2         1       1    1    2     3         1      3        0   \n",
      "2              3         1       3    1    1     1         0      2        1   \n",
      "3              4         1       1    1    2     3         0      3        0   \n",
      "4              5         0       3    0    2     1         0      1        1   \n",
      "..           ...       ...     ...  ...  ...   ...       ...    ...      ...   \n",
      "886          887         0       2    0    1     1         0      5        1   \n",
      "887          888         1       1    1    1     2         0      2        1   \n",
      "888          889         0       3    1    1     2         0      2        0   \n",
      "889          890         1       1    0    1     2         1      1        1   \n",
      "890          891         0       3    0    1     0         2      1        1   \n",
      "\n",
      "     Age*Class  \n",
      "0            3  \n",
      "1            2  \n",
      "2            3  \n",
      "3            2  \n",
      "4            6  \n",
      "..         ...  \n",
      "886          2  \n",
      "887          1  \n",
      "888          3  \n",
      "889          1  \n",
      "890          3  \n",
      "\n",
      "[891 rows x 10 columns],      PassengerId  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
      "0            892       3    0    2     0         2      1        1          6\n",
      "1            893       3    1    2     0         0      3        0          6\n",
      "2            894       2    0    3     1         2      1        1          6\n",
      "3            895       3    0    1     1         0      1        1          3\n",
      "4            896       3    1    1     1         0      3        0          3\n",
      "..           ...     ...  ...  ...   ...       ...    ...      ...        ...\n",
      "413         1305       3    0    1     1         0      1        1          3\n",
      "414         1306       1    1    2     3         1      5        1          2\n",
      "415         1307       3    0    2     0         0      1        1          6\n",
      "416         1308       3    0    1     1         0      1        1          3\n",
      "417         1309       3    0    1     2         1      4        0          3\n",
      "\n",
      "[418 rows x 9 columns]]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train_scaling.csv')\n",
    "test_df = pd.read_csv('./test_scaling.csv')\n",
    "combine = [train_df, test_df] # 데이터 프레임 두개를 한번에 저장한 리스트 타입의 변수 선언\n",
    "\n",
    "# preview the data\n",
    "train_df.info()\n",
    "print('_'*40)\n",
    "test_df.info()\n",
    "print('_'*40)\n",
    "print(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70d6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용 파일 제작\n",
    "Pid_df = test_df['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610304b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K fold 를 위한 데이터 분할\n",
    "index_train_df=train_df.drop(['Survived'], axis=1)\n",
    "y = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7121e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k fold는 배열로 이루어짐 -> 데이터 프레임을 배열로 변환\n",
    "X = np.array(index_train_df.iloc[:, :]) # survived 제외한 피처 전부 열들 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08608872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d78f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold 검증 과정으로 실제 랜덤 포레스트 모델을 학습하여 정확도 평균을 내는 방법\n",
    "def kFold(clf):\n",
    "    kf = KFold(n_splits = 5, shuffle = True)\n",
    "    accuracy_history = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train) # 모델 학습\n",
    "        y_pred = clf.predict(X_test) # 예측 라벨\n",
    "        \n",
    "        accuracy_history.append(accuracy_score(y_pred, y_test)) # 정확도 측정 및 기록\n",
    "    \n",
    "    print(\"사용한 모델 :\", clf)\n",
    "    print(\"각 분할의 정확도 기록 :\", accuracy_history)\n",
    "    print(\"평균 정확도 :\", np.mean(accuracy_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef48fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "perceptron = Perceptron()\n",
    "xgboost = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db0eef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용한 모델 : LogisticRegression()\n",
      "각 분할의 정확도 기록 : [0.8268156424581006, 0.8146067415730337, 0.7359550561797753, 0.7640449438202247, 0.8146067415730337]\n",
      "평균 정확도 : 0.7912058251208336\n",
      "사용한 모델 : DecisionTreeClassifier()\n",
      "각 분할의 정확도 기록 : [0.7821229050279329, 0.7584269662921348, 0.7808988764044944, 0.6629213483146067, 0.7134831460674157]\n",
      "평균 정확도 : 0.7395706484213169\n",
      "사용한 모델 : RandomForestClassifier()\n",
      "각 분할의 정확도 기록 : [0.8100558659217877, 0.8314606741573034, 0.7528089887640449, 0.797752808988764, 0.7808988764044944]\n",
      "평균 정확도 : 0.7945954428472788\n",
      "사용한 모델 : Perceptron()\n",
      "각 분할의 정확도 기록 : [0.6201117318435754, 0.5617977528089888, 0.6235955056179775, 0.38764044943820225, 0.6629213483146067]\n",
      "평균 정확도 : 0.5712133576046702\n",
      "사용한 모델 : XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "각 분할의 정확도 기록 : [0.7653631284916201, 0.8089887640449438, 0.7921348314606742, 0.7696629213483146, 0.7640449438202247]\n",
      "평균 정확도 : 0.7800389178331555\n"
     ]
    }
   ],
   "source": [
    "kFold(logreg)\n",
    "kFold(decision_tree)\n",
    "kFold(random_forest)\n",
    "kFold(perceptron)\n",
    "kFold(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a1c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logreg.predict(test_df)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": Pid_df,\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission_preprocessing_crossVal_LogisticRegression.csv', index=False)\n",
    "\n",
    "Y_pred = decision_tree.predict(test_df)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": Pid_df,\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission_preprocessing_crossVal_DecisionTree.csv', index=False)\n",
    "\n",
    "\n",
    "Y_pred = random_forest.predict(test_df)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": Pid_df,\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission_preprocessing_crossVal_RandomForest.csv', index=False)\n",
    "\n",
    "\n",
    "Y_pred = xgboost.predict(test_df)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": Pid_df,\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission_preprocessing_crossVal_XGboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d6865",
   "metadata": {},
   "source": [
    "# Submission 결과\n",
    "- k fold 방식에서는 오히려 성능 저하가 일어났음\n",
    "- 전부 classifier 모델이라 그럴수도?\n",
    "- 그렇다면 stratified K fold는? -> 실험 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff73626b",
   "metadata": {},
   "source": [
    "# cross_val_score 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a96072ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "\n",
    "def validation(clf):\n",
    "    print(clf)\n",
    "    score = cross_val_score(clf,X,y,scoring=scoring)\n",
    "    print(\"교차 검증 정확도:\", score)\n",
    "    print(\"교차 검증 평균:\", score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b95a2643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "교차 검증 정확도: [0.77653631 0.82022472 0.81460674 0.78089888 0.78089888]\n",
      "교차 검증 평균: 0.7946331052664617\n",
      "DecisionTreeClassifier()\n",
      "교차 검증 정확도: [0.67039106 0.7752809  0.61235955 0.79213483 0.79213483]\n",
      "교차 검증 평균: 0.728460234762413\n",
      "RandomForestClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 정확도: [0.67597765 0.79213483 0.81460674 0.80337079 0.83146067]\n",
      "교차 검증 평균: 0.78351013746783\n",
      "Perceptron()\n",
      "교차 검증 정확도: [0.62011173 0.61797753 0.61797753 0.61797753 0.39325843]\n",
      "교차 검증 평균: 0.573460548615906\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "교차 검증 정확도: [0.61452514 0.75842697 0.8258427  0.79213483 0.83146067]\n",
      "교차 검증 평균: 0.764478061640826\n"
     ]
    }
   ],
   "source": [
    "validation(logreg)\n",
    "validation(decision_tree)\n",
    "validation(random_forest)\n",
    "validation(perceptron)\n",
    "validation(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecc543",
   "metadata": {},
   "source": [
    "# logistic regression, RandomForest 가 가장 높은 정확도를 보임\n",
    "-> XGBoost가 갈수록 높아지는 정확도를 보임 -> 왜인지 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ff3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성 -> score 확인\n",
    "# 그 전에 prediction 진행\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습용, 테스트용 데이터 분할\n",
    "# y_train 구성\n",
    "y_train_df = train_df['Survived']\n",
    "# x_train 을 위한  survived 값 드롭\n",
    "X_train_df= train_df.drop('Survived',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_train_df, y_train_df, \\\n",
    "                                                  test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723eaa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dummy/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "logreg.fit(X_train,y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_test, y_test) * 100, 2) # accuracy percentage\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4be793aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "acc_random_forest = round(random_forest.score(X_test, y_test) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "raw",
   "id": "08471164",
   "metadata": {},
   "source": [
    "# VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_ensemble = VotingClassifier(estimators=[(\"Random Forest\",random_forest),\n",
    "                                               (\"XGBoost\",xgboost)],\n",
    "                                  voting = 'soft')\n",
    "voting_ensemble.fit(X_train, y_train)\n",
    "y_pred = voting_ensemble.predict(X_test)\n",
    "acc_voting_ensemble= round(voting_ensemble.score(X_test,y_test) * 100, 2)\n",
    "acc_voting_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49072f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pid_df = test_df['PassengerId']\n",
    "X_test_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71f70003",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logreg.predict(X_test_df)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": Pid_df,\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission_preprocessing_crossVal_LogisticRegression.csv', index=False)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test_df)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": Pid_df,\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission_preprocessing_crossVal_randomForest.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "493a5454",
   "metadata": {},
   "source": [
    "'''\n",
    "Y_pred = voting_ensemble.predict(X_test_df)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": Pid_df,\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "submission.to_csv('submission_preprocessing_voting_ensemble.csv', index=False)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
